<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>scrapy on Awesome Hugo blog</title><link>https://mugeliu.github.io/tags/scrapy/</link><description>Recent content in scrapy on Awesome Hugo blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 21 Apr 2022 17:33:49 +0000</lastBuildDate><atom:link href="https://mugeliu.github.io/tags/scrapy/index.xml" rel="self" type="application/rss+xml"/><item><title>深拷贝与浅拷贝问题的记录</title><link>https://mugeliu.github.io/posts/2022-04-21-%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B5%85%E6%8B%B7%E8%B4%9D%E9%97%AE%E9%A2%98%E7%9A%84%E8%AE%B0%E5%BD%95/</link><pubDate>Thu, 21 Apr 2022 17:33:49 +0000</pubDate><guid>https://mugeliu.github.io/posts/2022-04-21-%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B5%85%E6%8B%B7%E8%B4%9D%E9%97%AE%E9%A2%98%E7%9A%84%E8%AE%B0%E5%BD%95/</guid><description>深浅拷贝的问题记录 🖇️ 在抓取排行榜数据时，发现抓取的排行榜数据总是最后的一条。但是排行榜的数据量是没有问题的。在仔细检查逻辑后发现并没有什么问题。最后搜索排查是深浅拷贝的问题，遂记录一下。 原代码 &amp;#x1f447;
def parse_more_rank(self, response): items = response.meta.get(&amp;#34;items&amp;#34;) url_list = response.xpath(&amp;#39;//a[@class=&amp;#34;figure_pic&amp;#34;]/@href&amp;#39;).getall() ranking_list = response.xpath(&amp;#39;//a[@class=&amp;#34;figure_pic&amp;#34;]/span/text()&amp;#39;).getall() title_list = response.xpath(&amp;#39;//a[@class=&amp;#34;figure_pic&amp;#34;]/following-sibling::strong/a/text()&amp;#39;).getall() cover_id_list = [u.split(&amp;#39;cover/&amp;#39;)[1].split(&amp;#34;.&amp;#34;)[0] for u in url_list] for url,ranking,title,cover_id in zip(url_list,ranking_list,title_list,cover_id_list): items[&amp;#34;ranking&amp;#34;] = ranking items[&amp;#34;title&amp;#34;] = title items[&amp;#34;cover_id&amp;#34;] = cover_id yield scrapy.Request(url, callback=self.parse_detail, meta={&amp;#34;items&amp;#34;: items}, dont_filter=True) 程序运行到for循环都是没有问题的。到一个解析回调self.parse_detail的时候就出现了问题。存储的所有数据都是最后一条。（因为不同的排行榜中有相同的作品，所以没有过滤重复请求。）
最后排查是传递meta传递items的时候的问题，没有使用深拷贝，导致最后解析回调的时候都是同一个对象。
更改后
yield scrapy.Request(url, callback=self.parse_detail, meta=copy.deepcopy({&amp;#34;items&amp;#34;: items}), dont_filter=True) python赋值、深、浅拷贝 参考：
菜鸟教程
直接赋值： 其实就是对象的引用（别名）。
浅拷贝(copy)： 拷贝父对象，不会拷贝对象的内部的子对象。
深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。
2022-08-02更新 在scrapy文档中看到了关于item拷贝的API
yield scrapy.</description></item></channel></rss>